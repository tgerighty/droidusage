# Droid Usage Analyzer

A powerful CLI tool for analyzing Droid AI usage from local session files, inspired by ccusage for Claude Code. Get detailed insights into your AI usage patterns, costs, and session statistics.

## ğŸš€ Features

- ğŸ“Š **Daily Reports**: View token usage and costs aggregated by date
- ğŸ’¬ **Session Reports**: Detailed usage grouped by conversation sessions
- ğŸ¤– **Model Tracking**: See which AI models you're using (Claude, GPT-4, etc.)
- ğŸ“ˆ **Beautiful Tables**: Colorful table-formatted display with automatic responsive layout
- ğŸ“„ **JSON Output**: Export data in structured JSON format for integrations
- ğŸ“… **Date Filtering**: Filter reports by date range using `--since` and `--until`
- ğŸ’° **Cost Tracking**: Shows costs in USD for each day/session with accurate pricing
- ğŸ”„ **Cache Token Support**: Tracks and displays cache creation and cache read tokens separately
- â±ï¸ **Active Time Tracking**: Shows total active time for completed sessions (historical data)
- ğŸ” **Session Details**: Individual session breakdowns with timestamps and model information
- ğŸ¯ **Blocks Analysis**: Group sessions into 5-hour rolling windows for rate limit monitoring
- ğŸ’¬ **Prompt Counting**: Track actual user prompts sent (excluding automated tool results)
- âš¡ **High Performance**: Optimized for large datasets (1000+ sessions) with parallel processing and smart caching

## ğŸ“¦ Installation

### Prerequisites
- Node.js 14.0.0 or higher
- Factory AI installed (with session data in `~/.factory/sessions/`)

### Quick Install

```bash
# Clone the repository
git clone <repository-url>
cd droidusage

# Install dependencies
npm install

# Link for local usage
npm link

# Or install globally for easier access
npm install -g .
```

### Verify Installation

```bash
# Check that the tool is working
droidusage --help
```

## ğŸ¯ Usage

### Basic Commands

```bash
# Daily report (default) - Shows usage aggregated by day
droidusage daily

# Session report - Shows individual session details
droidusage session

# Blocks report - Groups sessions into 5-hour rolling windows
droidusage daily --blocks

# Both commands accept the same options
droidusage [daily|session] [options]
```

### Command Options

| Option | Description | Example |
|--------|-------------|---------|
| `--sessions-dir <path>` | Path to Factory sessions directory | `--sessions-dir /custom/path/.factory/sessions` |
| `--since <date>` | Filter sessions from this date (inclusive) | `--since 2025-10-01` |
| `--until <date>` | Filter sessions until this date (inclusive) | `--until 2025-10-31` |
| `--blocks` | Group sessions into 5-hour rolling windows for rate limit analysis | `--blocks` |
| `--json` | Output results in JSON format instead of tables | `--json` |
| `--help` | Show help information | `--help` |
| `--version` | Show version number | `--version` |

### Usage Examples

```bash
# Basic daily usage report
droidusage daily

# Show sessions for specific date range
droidusage daily --since 2025-10-01 --until 2025-10-07

# Export data as JSON for external processing
droidusage session --json

# Analyze rate limits with 5-hour blocks
droidusage daily --blocks

# Check recent 5-hour windows for usage patterns
droidusage session --blocks --since 2025-10-08

# Analyze specific time period
droidusage daily --since 2025-10-08

# Use custom sessions directory
droidusage daily --sessions-dir /backup/.factory/sessions

# Get detailed session information for the last week
droidusage session --since $(date -d '7 days ago' +%Y-%m-%d)
```

## ğŸ“Š What It Analyzes

The tool analyzes Factory AI session data from two types of files:

### Data Sources
- **Session Logs**: `[uuid].jsonl` - Contains conversation messages, timestamps, and interactions
- **Session Settings**: `[uuid].settings.json` - Contains aggregated token usage and metadata

### Metrics Tracked
- **Input Tokens**: Tokens sent to the AI model
- **Output Tokens**: Tokens generated by the AI model
- **Cache Creation Tokens**: Tokens written to cache
- **Cache Read Tokens**: Tokens read from cache (more cost-effective)
- **Thinking Tokens**: Tokens used for internal reasoning (Claude models)
- **User Prompts**: Number of actual user messages sent (excludes automated tool results)
- **Active Time**: Duration of active AI interaction per session
- **Model Information**: Which AI model was used for each session
- **Cost Calculation**: Monetary cost based on current model pricing

## ğŸ“ˆ Output Examples

### Daily Report Format

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Date       â”‚ Models                       â”‚ Input â”‚ Output â”‚ Cache Create â”‚ Cache Read â”‚ Total Tokens â”‚ Cost (USD) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-10-04 â”‚ â€¢ claude-3-5-sonnet-20241022 â”‚ 2,460 â”‚ 2,378  â”‚ 0            â”‚ 8,320      â”‚ 13,158       â”‚ $0.04      â”‚
â”‚            â”‚ â€¢ gpt-4o                     â”‚       â”‚        â”‚              â”‚            â”‚              â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-10-08 â”‚ â€¢ claude-3-5-sonnet-20241022 â”‚ 0     â”‚ 56,727 â”‚ 0            â”‚ 0          â”‚ 56,727       â”‚ $0.85      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Summary:
  Total Sessions: 4
  Total Tokens: 115,212
  Total Cost: $1.57
  Total Active Time: 2h
```

### Session Report Format

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session ID  â”‚ Date             â”‚ Model                      â”‚ Input â”‚ Output â”‚ Cache â”‚ Total  â”‚ Cost  â”‚ Active Time â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 545fbc97... â”‚ 2025-10-08 09:46 â”‚ claude-3-5-sonnet-20241022 â”‚ 0     â”‚ 47,622 â”‚ 0     â”‚ 47,622 â”‚ $0.71 â”‚ 43m         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 65109a7e... â”‚ 2025-10-04 23:51 â”‚ gpt-4o                     â”‚ 2,460 â”‚ 401    â”‚ 8,320 â”‚ 11,181 â”‚ $0.01 â”‚ 7s          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Summary:
  Total Sessions: 12
  Total Tokens: 115,311
  Total Cost: $1.57
  Total Active Time: 2h
```

### Blocks Report Format

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Date       â”‚ Time Block    â”‚ Model(s)             â”‚ Sessions â”‚ Input   â”‚ Output    â”‚ Cache Create â”‚ Cache Read â”‚ Total Tokens â”‚ Prompts â”‚ Cost (USD) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-10-04 â”‚ 23:51 - 04:51 â”‚ glm-4.6, gpt-5-codex â”‚ 2        â”‚ 2,460   â”‚ 596,699   â”‚ 0            â”‚ 8,320      â”‚ 607,479      â”‚ 6       â”‚ $4.49      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-10-06 â”‚ 05:51 - 10:51 â”‚ glm-4.6              â”‚ 1        â”‚ 0       â”‚ 296,172   â”‚ 0            â”‚ 0          â”‚ 296,172      â”‚ 1       â”‚ $0.00      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-10-08 â”‚ 07:51 - 12:51 â”‚ glm-4.6              â”‚ 4        â”‚ 0       â”‚ 818,783   â”‚ 0            â”‚ 0          â”‚ 818,783      â”‚ 21      â”‚ $0.00      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Summary:
  Total Sessions: 7
  Total Tokens: 1,722,334
  Total Prompts: 28
  Total Cost: $4.49
  Total Active Time: 1h
```

### JSON Output Format

```json
{
  "type": "daily",
  "data": [
    {
      "date": "2025-10-08",
      "models": ["claude-3-5-sonnet-20241022"],
      "inputTokens": 0,
      "outputTokens": 56727,
      "cacheCreationTokens": 0,
      "cacheReadTokens": 0,
      "totalTokens": 56727,
      "userInteractions": 23,
      "cost": 0.85,
      "sessions": [...]
    }
  ],
  "summary": {
    "totalSessions": 4,
    "totalTokens": 115212,
    "totalCost": 1.57,
    "totalActiveTime": 7200000,
    "totalPrompts": 116
  }
}
```

## ğŸ’° Pricing Information

The tool calculates costs based on current AI model pricing (subject to change):

### Anthropic Claude Models
| Model | Input | Output | Cache Read | Cache Write |
|-------|--------|--------|-------------|-------------|
| Claude 3.5 Sonnet | $3.00/M | $15.00/M | $0.30/M | $3.75/M |
| Claude 3.5 Haiku | $0.80/M | $4.00/M | $0.08/M | $1.00/M |

### OpenAI GPT Models
| Model | Input | Output | Cache Read | Cache Write |
|-------|--------|--------|-------------|-------------|
| GPT-4o | $2.50/M | $10.00/M | $0.125/M | $2.50/M |
| GPT-4o Mini | $0.15/M | $0.60/M | $0.075/M | $0.30/M |

*Prices are shown per million tokens and are subject to change by providers.*

## ğŸ”§ Advanced Usage

### Rate Limit Analysis with Blocks

The `--blocks` option groups sessions into **5-hour rolling windows** starting from your first session, making it easy to monitor usage against rate limits:

```bash
# Monitor rate limits for models with 200 prompts per 5 hours
droidusage daily --blocks

# Check if you're approaching limits
droidusage daily --blocks --json | jq -r '.data[] | select(.userPrompts > 150)'
```

**Block Analysis Benefits:**
- **Rolling Windows**: 5-hour periods that start from your first message (not midnight)
- **Multiple Models**: See which models are used in each time block
- **Prompt Counting**: Track actual user prompts to stay within limits
- **Cost Tracking**: Monitor costs during high-usage periods

### Integration with Scripts

```bash
#!/bin/bash
# Get daily cost report
COST_REPORT=$(droidusage daily --json)

# Extract total cost
TOTAL_COST=$(echo $COST_REPORT | jq -r '.summary.totalCost')

# Send alert if cost exceeds threshold
if (( $(echo "$TOTAL_COST > 10.0" | bc -l) )); then
    echo "âš ï¸  Daily AI usage cost: $${TOTAL_COST} exceeds $10.00"
fi

# Check prompt usage against rate limits
BLOCKS_REPORT=$(droidusage daily --blocks --json)
HIGH_USAGE_BLOCKS=$(echo $BLOCKS_REPORT | jq -r '.data[] | select(.userPrompts > 180)')
if [ -n "$HIGH_USAGE_BLOCKS" ]; then
    echo "âš ï¸  Approaching rate limit in some 5-hour blocks"
fi
```

### Monitoring Usage

```bash
# Create a daily usage log
echo "$(date): $(droidusage daily --json | jq -r '.summary.totalCost')" >> usage_log.txt

# Weekly summary with blocks
droidusage daily --since $(date -d '7 days ago' +%Y-%m-%d) --json

# Rate limit monitoring
droidusage daily --blocks --since $(date -d '24 hours ago' +%Y-%m-%d)
```

## ğŸ› Troubleshooting

### Common Issues

**"No session data found"**
- Ensure Factory AI has been used and sessions exist
- Check that `~/.factory/sessions/` directory exists and contains files
- Verify permissions on the sessions directory

**"Cannot read sessions directory"**
- Check the path provided with `--sessions-dir`
- Ensure the directory is accessible and readable
- Verify proper file permissions

**Empty token counts**
- Some sessions may not have token usage recorded yet
- Sessions with no AI interactions will show 0 tokens
- Check if the session files are complete

**Inaccurate prompt counts**
- The tool counts only actual user messages, not tool results
- System messages and automated responses are excluded
- This provides accurate tracking for rate limit analysis

### Debug Mode

Set the `DEBUG` environment variable for detailed error information:

```bash
DEBUG=1 ./bin/factory-usage.js daily
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Create a feature branch**: `git checkout -b feature/amazing-feature`
2. **Make your changes** and add tests if applicable
3. **Ensure everything works**: `npm test`
4. **Commit your changes**: `git commit -m 'Add amazing feature'`
5. **Share your changes** with the community

### Development Setup

```bash
# Clone the repository
git clone <repository-url>
cd droidusage

# Install dependencies
npm install

# Run tests
npm test

# Link for local development
npm link
```

## ğŸ§ª Testing

This project includes a comprehensive test suite to ensure reliability and correctness of the usage analysis functionality.

### Running Tests

```bash
# Run all tests
npm test

# Run tests in watch mode (re-runs on file changes)
npm run test:watch

# Run tests with coverage report
npm run test:coverage

# Run specific test file
npm test -- __tests__/analyzer.test.js

# Run tests matching a pattern
npm test -- --testNamePattern="pricing"
```

### Test Coverage

The test suite provides **75.99% code coverage** and includes:

- **65 test cases** covering all major functionality
- **Unit tests** for individual methods and functions
- **Integration tests** for end-to-end workflows
- **Error handling tests** for edge cases and failure scenarios

### Test Structure

```
__tests__/
â”œâ”€â”€ analyzer.test.js      # Core functionality tests
â”œâ”€â”€ parsing.test.js       # Log parsing and data extraction tests
â”œâ”€â”€ integration.test.js   # End-to-end workflow tests
â””â”€â”€ performance.test.js   # Performance optimization tests (NEW)
```

### What's Tested

âœ… **Core Functionality**
- Pricing configuration for all providers (GLM, GPT-5, Claude)
- Model name normalization and detection
- Cost calculations with real pricing data
- Number/cost/time formatting utilities

âœ… **Data Processing**
- Token aggregation from multiple sources
- Session grouping by date and model
- Log parsing and timestamp extraction
- Model inference from session data

âœ… **Error Handling**
- Corrupted or invalid JSON files
- Missing session files or directories
- Invalid timestamps and malformed data
- Empty or incomplete session data

âœ… **Integration Scenarios**
- Multi-session daily reports
- Mixed provider usage patterns
- Real-world usage workflows
- JSON output generation

### Test Data

Tests use realistic sample data including:
- Sample Factory session files (`*.settings.json`)
- Simulated log entries (`droid-log-single.log`)
- Various model usage patterns and token data
- Edge cases and error scenarios

### Coverage Report

Running `npm run test:coverage` generates a detailed coverage report in the `coverage/` directory:
- **HTML report**: Open `coverage/lcov-report/index.html` in your browser
- **Text summary**: Shows percentage coverage for files, functions, branches, and lines
- **LCOV format**: For integration with CI/CD systems

### Writing New Tests

When adding new features, please include tests:

```javascript
// Example test structure
describe('New Feature', () => {
  test('should handle new functionality correctly', () => {
    // Arrange
    const input = createTestData();
    
    // Act
    const result = analyzer.newFeature(input);
    
    // Assert
    expect(result).toBeDefined();
    expect(result.someProperty).toBe(expectedValue);
  });
});
```

### Test Best Practices

- **Test naming**: Use descriptive test names that explain what's being tested
- **Arrange-Act-Assert**: Structure tests clearly with setup, execution, and verification
- **Edge cases**: Test both happy paths and error conditions
- **Realistic data**: Use sample data that reflects real-world usage
- **Isolation**: Each test should be independent and not rely on other tests

### Continuous Integration

The test suite is designed to run in CI/CD environments:
- Fast execution (< 1 second)
- No external dependencies required
- Self-contained test data
- Clear pass/fail output

For more details, see the [Jest documentation](https://jestjs.io/docs/getting-started).

## âš¡ Performance

The tool is optimized for large datasets with the following improvements:

### Performance Optimizations (v1.2.0)

- **Smart Caching**: Log files are parsed once and indexed for O(1) lookup
- **Parallel Processing**: Sessions processed in batches of 50 simultaneously
- **Lazy Loading**: Prompt counting only when needed (blocks report)
- **Progress Indicators**: Visual feedback for large datasets (>100 sessions)

### Benchmark Results

| Sessions | Time (Before) | Time (After) | Improvement |
|----------|--------------|--------------|-------------|
| 100      | ~10-20s      | <1s          | **20Ã— faster** |
| 500      | ~2-5min      | ~2-3s        | **60Ã— faster** |
| 1000     | ~10-20min    | ~5-10s       | **100Ã— faster** |
| 5000     | ~50-100min   | ~30-60s      | **100Ã— faster** |

**Key optimizations:**
- âœ… Read log file once instead of per-session (1000Ã— reduction in I/O)
- âœ… Process 50 sessions in parallel instead of sequential
- âœ… Skip unnecessary prompt counting for daily/session reports
- âœ… Display progress for better user experience

See [PERFORMANCE_OPTIMIZATIONS.md](PERFORMANCE_OPTIMIZATIONS.md) for technical details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### MIT License Summary

```
MIT License

Copyright (c) 2025 Droid Usage Analyzer

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ™ Acknowledgments

- Inspired by [ccusage](https://github.com/ryoppippi/ccusage) for Claude Code
- Built for the Droid AI community
- Thanks to all contributors and users who help improve this tool

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the [Troubleshooting](#-troubleshooting) section above
2. Report issues with detailed information about your problem
3. Include the output with `DEBUG=1` for better assistance

---

**Happy analyzing! ğŸš€**
